{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d6f6439-d546-49b4-a571-44e23794d400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceTextGenInference\n",
    "\n",
    "llm = HuggingFaceTextGenInference(\n",
    "    inference_server_url=\"http://172.17.0.4:80\",\n",
    "    max_new_tokens=512,\n",
    "    top_k=10,\n",
    "    top_p=0.95,\n",
    "    typical_p=0.95,\n",
    "    temperature=0.10,\n",
    "    repetition_penalty=1.03\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c7cbf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67731b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\hbui11\\appdata\\local\\anaconda3\\lib\\site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\hbui11\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (2.29.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hbui11\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hbui11\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (3.8.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hbui11\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hbui11\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hbui11\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hbui11\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hbui11\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hbui11\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\hbui11\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hbui11\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hbui11\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hbui11\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hbui11\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d2e6450-de00-4eac-8a92-adb1b4e93a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceTextGenInference, OpenAI\n",
    "from llama_index import ServiceContext, LLMPredictor, OpenAIEmbedding, PromptHelper\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.langchain_helpers.text_splitter import TokenTextSplitter\n",
    "\n",
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "llm_predictor = LLMPredictor(llm=llm)\n",
    "embed_model = OpenAIEmbedding()\n",
    "node_parser = SimpleNodeParser(text_splitter=TokenTextSplitter(chunk_size=1000, chunk_overlap=100))\n",
    "prompt_helper = PromptHelper(context_window=1512, num_output=256, chunk_overlap_ratio=0.1, chunk_size_limit=None)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "  llm_predictor=llm_predictor,\n",
    "  embed_model=embed_model,\n",
    "  node_parser=node_parser,\n",
    "  prompt_helper=prompt_helper\n",
    ")\n",
    "\n",
    "from llama_index import set_global_service_context\n",
    "set_global_service_context(service_context)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "216de455-5f2b-4258-b982-cfff82632c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76c3b5cf-e05f-4d2f-a34b-fc5e5e9b4a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_index import download_loader\n",
    "from langchain.agents import create_csv_agent\n",
    "\n",
    "# import pandas as pd\n",
    "# from langchain.agents import create_pandas_dataframe_agent\n",
    "# from langchain.agents.agent_types import AgentType\n",
    "\n",
    "\n",
    "PagedCSVReader = download_loader(\"PagedCSVReader\")\n",
    "\n",
    "loader = PagedCSVReader(encoding=\"utf-8\")\n",
    "documents = loader.load_data(file=Path('./2019.csv'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c0d3ed4-66e1-4736-84f8-6d87f34a644c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      5\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msk-ptlAy9hhROWcfIkpxiTpT3BlbkFJYtX2tPmK1mNCQciHB2Nl\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m load_dotenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai.env\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]='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'\n",
    "load_dotenv(\"openai.env\")\n",
    "openai.api_key=os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9771718f-99d2-4f5d-ac7e-922a89dfdb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents,service_context=service_context)\n",
    "# index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "526aebd8-6a36-4013-ab6b-ff1347fedef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.indices.loading:Loading all indices.\n",
      "Loading all indices.\n",
      "Loading all indices.\n"
     ]
    }
   ],
   "source": [
    "index.storage_context.persist()\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "\n",
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
    "# load index\n",
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "73475648-e5b6-4b4c-b809-8628d105e04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "> [retrieve] Total LLM token usage: 0 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [retrieve] Total embedding token usage: 9 tokens\n",
      "> [retrieve] Total embedding token usage: 9 tokens\n",
      "> [retrieve] Total embedding token usage: 9 tokens\n",
      "> [retrieve] Total embedding token usage: 9 tokens\n",
      "> [retrieve] Total embedding token usage: 9 tokens\n",
      "> [retrieve] Total embedding token usage: 9 tokens\n",
      "> [retrieve] Total embedding token usage: 9 tokens\n",
      "> [retrieve] Total embedding token usage: 9 tokens\n",
      "> [retrieve] Total embedding token usage: 9 tokens\n",
      "> [retrieve] Total embedding token usage: 9 tokens\n",
      "> [retrieve] Total embedding token usage: 9 tokens\n",
      "> [retrieve] Total embedding token usage: 9 tokens\n",
      "> [retrieve] Total embedding token usage: 9 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total LLM token usage: 137 tokens\n",
      "> [get_response] Total LLM token usage: 137 tokens\n",
      "> [get_response] Total LLM token usage: 137 tokens\n",
      "> [get_response] Total LLM token usage: 137 tokens\n",
      "> [get_response] Total LLM token usage: 137 tokens\n",
      "> [get_response] Total LLM token usage: 137 tokens\n",
      "> [get_response] Total LLM token usage: 137 tokens\n",
      "> [get_response] Total LLM token usage: 137 tokens\n",
      "> [get_response] Total LLM token usage: 137 tokens\n",
      "> [get_response] Total LLM token usage: 137 tokens\n",
      "> [get_response] Total LLM token usage: 137 tokens\n",
      "> [get_response] Total LLM token usage: 137 tokens\n",
      "> [get_response] Total LLM token usage: 137 tokens\n",
      "INFO:llama_index.token_counter.token_counter:> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "> [get_response] Total embedding token usage: 0 tokens\n",
      "\n",
      "A) United States\n",
      "B) Switzerland\n",
      "C) Norway\n",
      "D) Qatar\n",
      "\n",
      "Please select one of the options from the table above.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    # response_mode=\"\", \n",
    "    verbose=True, \n",
    "    similarity_top_k=1)\n",
    "response = query_engine.query(\"Which country has the highest GDP per capita?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1ff7ff12-53bc-4959-a783-625282e89b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5140b70a-9d88-4719-8b5f-6d3feb070d26",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-ptlAy9hhROWcfIkpxiTpT3BlbkFJYtX2tPmK1mNCQciHB2Nl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# openai_api_key = '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'\u001b[39;00m\n\u001b[0;32m      4\u001b[0m agent \u001b[38;5;241m=\u001b[39m create_csv_agent(\n\u001b[1;32m----> 5\u001b[0m     ChatOpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo-16k\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2019.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      8\u001b[0m     agent_type\u001b[38;5;241m=\u001b[39mAgentType\u001b[38;5;241m.\u001b[39mOPENAI_FUNCTIONS,\n\u001b[0;32m      9\u001b[0m     \n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     11\u001b[0m response1 \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mrun(user_question)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain\\load\\serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for ChatOpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "# openai_api_key = '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'\n",
    "agent = create_csv_agent(\n",
    "    ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-16k\"),\n",
    "    \"2019.csv\",\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.OPENAI_FUNCTIONS,\n",
    "    \n",
    ")\n",
    "response1 = agent.run(user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55c30205-556e-4284-8d57-4a1e66b43d1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(response1)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'response1' is not defined"
     ]
    }
   ],
   "source": [
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f120e339-4b65-4977-b9d2-065f455bd7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
